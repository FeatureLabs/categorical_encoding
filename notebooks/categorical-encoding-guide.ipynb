{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Guide for Applying Categorical Encoding Methods\n",
    "\n",
    "In this notebook, we will be investigating the most common approaches to categorical encoding and how it can integrate into Featuretools software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "When applying machine learning, we most commonly deal with two types of structured data: numeric data (ex: `Age`: [1,2,3]) and categorical data (ex: `color`: ['red', 'blue', 'green']). \n",
    "\n",
    "It is often easier to deal with numeric data compared to categorical data because machine learning models typically deal with mathematical vectors--numeric data can thus be used without as many additional complexities. \n",
    "\n",
    "However, machine learning algorithms cannot work directly with categorical data and therefore we must do some amount of transformations and engineering on our data before continuing, making categorical encoding an essential part of feature engineering. We will look at some of the most common approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Encoding Flowchart\n",
    "\n",
    "Below is a graphic overview of how to decide which categorical encoding approach to use. Use this flowchart as a rough guide as to how some encoders might perform better in certain situations.\n",
    "\n",
    "![Categorical%20Encoding%20Flowchart.png](../flowchart/Categorical%20Encoding%20Flowchart.png)\n",
    "\n",
    "In this notebook, we will be exploring the encoding approaches detailed in this flowchart as well as the [Category Encoders Library](http://contrib.scikit-learn.org/categorical-encoding/index.html), which is maintained by [Will McGinnis](http://www.willmcginnis.com) and based off of [patsy](https://patsy.readthedocs.io/en/latest/API-reference.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format #increase readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Data\n",
    "\n",
    "Categorical data is defined as variables that can take one of possible values, specifically on the basis of a qualitative property rather than strictly quantitative. One example of categorical data are the 50 US States--`California` and `Massachusetts` are two distinct values but are not based solely off of numeric attributes.\n",
    "\n",
    "### Nominal vs. Categorical Data\n",
    "\n",
    "The categorical encoding approach can vary significantly depending on which of the two major types of categorical variables the data falls under.\n",
    "\n",
    "#### Nominal Data\n",
    "First, we have nominal data, which have no meaningful ordering. \n",
    "\n",
    "Examples of this include our previously mentioned US States (`California`, `Massachusetts`, `New York`...), music genres (`Classical`, `Hip-hop`, `Jazz`...), or cuisine types (`Chinese`, `Italian`, `Tex-Mex`...).\n",
    "\n",
    "#### Ordinal Data\n",
    "\n",
    "On the other hand, we have ordinal data, which do have a meaningful ordering. \n",
    "\n",
    "Examples of this include t-shirt sizes (`XS`, `S`, `M`, `L`, `XL`), survey opinions (`strongly dislike`, `dislike`, `like`, `strongly like`), or socieconomic status/income categories (`0-$50000`, `$50000-$100000`, `$100000+`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic Encoders\n",
    "\n",
    "These encompass a broad range of encoders that are the most straightfoward and easiest to understand, making them very useful and popular among ML practioners.\n",
    "\n",
    "### Ordinal/Label Encoding\n",
    "\n",
    "This is the most straightforward approach to categorical encoding, and is often used as a first step in categorical encoding before applying other encoders.\n",
    "\n",
    "Ordinal Encoders convert each category value into a whole number. Specifically, the first unique value in the column is assigned to 1, the second unique value becomes 2, and so on.\n",
    "\n",
    "However, usually keeping the data like this is not recommended, especially if the data is nominal. Machine Learning algorithms will assume this variable is continuous, and thus will either assume an ordering that is either incorrect or does not exist. \n",
    "\n",
    "For example, if we assign `California`=1, `Massachusetts`=2, `New York`=3, then the algorithm may assume the ordering `California`<`Massachusetts`<`New York` because it interprets it as $1<2<3$. However, ordering states like that in this context is nonsensical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state\n",
       "0    CA\n",
       "1    MA\n",
       "2    CA\n",
       "3    NY\n",
       "4    CA\n",
       "5    NY"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'state':[\"CA\", \"MA\", \"CA\", \"NY\", \"CA\", \"NY\"]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the Ordinal Encoder, it looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state\n",
       "0      1\n",
       "1      2\n",
       "2      1\n",
       "3      3\n",
       "4      1\n",
       "5      3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_ord = ce.OrdinalEncoder(cols = ['state'])\n",
    "ce_ord.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though, as explained earlier, this encoding is unusable for direct application into an ML algorithm, it can still be useful to first convert the column into integers. \n",
    "\n",
    "One major reason is that many categorical encoders in third-party libraries require the categorical features to be integers. \n",
    "\n",
    "`sklearn`'s `OneHotEncoder` function:\n",
    "\n",
    "> Encode(s) categorical **integer** features using a one-hot aka one-of-K\n",
    "> scheme. (see [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html))\n",
    "\n",
    "Thus, it is necessary to first use Ordinal Encoding before one is able to use other encoding methods.\n",
    "\n",
    "However, for **interval data**, an ordinal encoder is useful assuming that one assigns the correct numbers to the correct values. Namely, if we had t-shirt sizes `[S,M,L]`, we'd want them to map to `[1,2,3]`, not `[1,3,2]`. This can be handled according to the encoder.\n",
    "\n",
    "Otherwise, if the variable is nominal or does not increase evenly, then one should use another encoder before passing in the data to an ML algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHot/Dummy Encoding\n",
    "\n",
    "One-hot encoding is by far the most popular approach for categorical encoding due to its ease to use/understand, versatility, and accuracy. \n",
    "\n",
    "One-hot encoding works by creating a new column for each value. For each new column, a 1 is assigned if the row contains that column's value and a 0 otherwise.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_1</th>\n",
       "      <th>state_2</th>\n",
       "      <th>state_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_1  state_2  state_3\n",
       "0        1        0        0\n",
       "1        0        1        0\n",
       "2        1        0        0\n",
       "3        0        0        1\n",
       "4        1        0        0\n",
       "5        0        0        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_one_hot = ce.OneHotEncoder(cols = ['state'])\n",
    "ce_one_hot.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that rows 0, 2, 4, which correspond to `CA`, all have rows `[1,0,0]`. `MA` corresponds to `[0,1,0]` and `NY` correponds to `[0,0,1]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding typically performs very well, and Featuretools' `encode_features` currently utilizes this. There is one major drawback, however.\n",
    "\n",
    "The number of new features generated is equal to the number of unique values, which leads to severe memory issues with high cardinality datasets. Furthermore, one-hot encoded data can [degrade the performance of decision-tree based algorithms](https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/).\n",
    "\n",
    "For an example of how high cardinality can affect performance, imagine if we had a dataset containing all 50 states rather than just 3 in our example. Then, we could go from originally one column to fifty columns, increasing the dimensionality of our matrix greatly.\n",
    "\n",
    "With even higher cardinality and large datasets, memory can become a serious concern, especially as one-hot encoding leads to extremely sparse matrices (as they are filled mostly with 0's). This leads to our next series of approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Encoding\n",
    "\n",
    "In Binary Encoding, the categories' values, if not already in numeric form, are Ordinal Encoded. The resulting integers are converted to binary, and then the digits are split into columns. For example, `5` would become three columns `[1,0,1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_0</th>\n",
       "      <th>state_1</th>\n",
       "      <th>state_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_0  state_1  state_2\n",
       "0        0        0        1\n",
       "1        0        1        0\n",
       "2        0        0        1\n",
       "3        0        1        1\n",
       "4        0        0        1\n",
       "5        0        1        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_bin = ce.BinaryEncoder(cols = ['state'])\n",
    "ce_bin.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates fewer columns than one-hot, and thus is more memory efficient and can reduce dimensionality problems.\n",
    "\n",
    "Furthermore, similar values may overlap with each other across multiple columns, allowing for machine learning algorithms to learn similarities. \n",
    "\n",
    "However, on the other hand, binary encoding can thus imply similiarities where it may not exist, so it really only excels for ordinal data with high cardinality. \n",
    "\n",
    "It is typically worth a shot to try binary encoding if one-hot encoding fails. However, for nominal data, typically another approach such as **Hashing** (which gives more control) would make more sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing Encoding\n",
    "\n",
    "Hashing Encoders employ the [hashing trick](https://medium.com/value-stream-design/introducing-one-of-the-best-hacks-in-machine-learning-the-hashing-trick-bf6a9c8af18f), which you can also read more about [here](https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087).\n",
    "\n",
    "Essentially, it is similar to one-hot encoding, except it uses a hashing algorithm to map values. For high cardinality datasets, it creates fewer new dimensions but comes at the cost of some information loss due to collisions. However, these collisions do not typically cause problems unless there's a lot of overlap.\n",
    "\n",
    "When dealing with high cardinality, it is worth trying because it gives you more control than a binary encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_7\n",
       "0      0      1      0      0      0      0      0      0\n",
       "1      0      0      0      0      1      0      0      0\n",
       "2      0      1      0      0      0      0      0      0\n",
       "3      1      0      0      0      0      0      0      0\n",
       "4      0      1      0      0      0      0      0      0\n",
       "5      1      0      0      0      0      0      0      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_hash = ce.HashingEncoder(cols = ['state'], n_components=8)\n",
    "ce_hash.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `n_components` is 8 by default, but can be changed to be less than `k` (number of unique values/number of columns created by one-hot encoding).\n",
    "\n",
    "The specific hashing algorithm can be changed (default is _md5_), giving the user more control as well as possibly grouping similar categories together within the same/similar hash value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Encoders\n",
    "\n",
    "Sometimes one does not want the info loss that comes with Hashing or Binary encoding, but one-hot encoding will not work because of high cardinality. This is when Bayesian Encoders could be extremely useful.\n",
    "\n",
    "Bayesian Encoders use information from the dependent variable in their encodings. It outputs only one column, and thus works well with high cardinality data. \n",
    "\n",
    "For example, we will take our previous example with states and change up the problem. Imagine that each row now corresponds to an individual with two attributes: the state that they're from and the number of cars they own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>cars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  cars\n",
       "0    CA     3\n",
       "1    MA     1\n",
       "2    CA     2\n",
       "3    NY     0\n",
       "4    CA     4\n",
       "5    NY     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'state':[\"CA\", \"MA\", \"CA\", \"NY\", \"CA\", \"NY\"],\n",
    "    'cars':[3,1,2,0,4,1]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encoding\n",
    "\n",
    "Arguably the most straightforward of the Bayesian Encoders, Target Encoding uses the mean of the dependent variable but one must take steps to avoid overfitting/response leakage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state\n",
       "0   2.86\n",
       "1   1.83\n",
       "2   2.86\n",
       "3   0.86\n",
       "4   2.86\n",
       "5   0.86"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_targ = ce.TargetEncoder(cols = ['state'])\n",
    "ce_targ.fit_transform(df['state'], df['cars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the state column has now been replaced by a value calculated from the mean of the cars column pertaining to that particular category.\n",
    "\n",
    "`Category Encoder`'s `TargetEncoder` [function](http://contrib.scikit-learn.org/categorical-encoding/targetencoder.html):\n",
    "\n",
    ">Target encoding for categorical features.\n",
    "\n",
    ">For the case of categorical target: features are replaced with a blend of posterior probability of the target given particular categorical value and the prior probability of the target over all the training data.\n",
    "\n",
    ">For the case of continuous target: features are replaced with a blend of the expected value of the target given particular categorical value and the expected value of the target over all the training data.\n",
    "\n",
    "Specifically, note how `CA` has been replaced by `2.86`.\n",
    "\n",
    "You can experiment with different TargetEncoders/your own version to see what the best fit for your model is.\n",
    "\n",
    "However, we can see how issues with overfitting and label leakage could quickly arise. If we now wished to predict the number of cars someone owned based on what state they lived in (in addition to other factors), our state column would then leak information.\n",
    "\n",
    "Similarly, if we were trying to predict someone's income from the state they lived in, the number of cars they owned, and other factors, there's a high chance that we would overfit to the number of cars they owned.\n",
    "\n",
    "Thus, the need arises for a similar encoder that can take care of these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeaveOneOut Encoding\n",
    "\n",
    "This is very similar to LeaveOneOut, except the row in question leaves its own value out when calculating the mean to avoid contamination.\n",
    "\n",
    "This is used by Owen Zhang a lot in Kaggle competitions, and he swears by it. You can read more about his take on it and more [here](https://www.slideshare.net/OwenZhang2/tips-for-data-science-competitions).\n",
    "\n",
    "In general, just like all Bayesian encoders, it can help split up larger categories logically and fit/group certain categories together better.\n",
    "\n",
    "However, its main advantage over other encoders is that it takes care of the overfitting and label leakage problem. Although, it is less straightforward compared to other encoders, which may present additional difficulties during the machine learning model process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state\n",
       "0   3.00\n",
       "1   1.83\n",
       "2   3.50\n",
       "3   1.00\n",
       "4   2.50\n",
       "5   0.00"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_leave = ce.LeaveOneOutEncoder(cols = ['state'])\n",
    "ce_leave.fit_transform(df['state'], df['cars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how each row has a different value. This reduces label leakage, and with a more substantial number of rows, should not vary greatly from category to category.\n",
    "\n",
    "One thing that one must keep in mind is that train/test data must be split before applying the encoder. Otherwise, you will leak information from your test data into your training data. This requires more care when encoding compared to something like a OneHotEncoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Bayesian Encoders\n",
    "\n",
    "In certain situations, other encoders may work better. However, these encoders are not as commonly used for Kaggle competitions and real-life applications, but it may help to check these encoders if you want to/have the time.\n",
    "\n",
    "We will briefly go over each of the encoders.\n",
    "\n",
    "#### [Weights of Evidence](https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html)\n",
    "\n",
    "WoE tells the predictive power of an independent variable in relation to the dependent variable. Namely, it's calculated through: $$\\text{WOE} = \\ln{\\frac{\\text{Distribution of non-events}}{\\text{Distribution of events}}}.$$\n",
    "\n",
    "More specifically, it is a way to separate \"Goods\" from \"Bads.\" As this evolved from the credit scoring world, one example is separating \"good customers,\" ones who do not default on a loan, from \"bad customers,\" who default on a loan. Then, for a particular category, say a specific state such as \"California,\" we take the natural log of the quotient of the percentage of good customers over the percentage of bad customers.\n",
    "\n",
    "Each category (bin) must be non-zero and contain at least 5% of the total observations.\n",
    "\n",
    "WOE is especially useful in certain cases, because categories with similar WOE's are typically also similar, which could help with the accuracy of a machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state  owns car\n",
      "0    CA         1\n",
      "1    MA         1\n",
      "2    CA         1\n",
      "3    NY         1\n",
      "4    CA         0\n",
      "5    NY         0\n",
      "6    MA         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state\n",
       "0   0.22\n",
       "1  -0.18\n",
       "2   0.22\n",
       "3  -0.18\n",
       "4   0.22\n",
       "5  -0.18\n",
       "6  -0.18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({\n",
    "    'state':[\"CA\", \"MA\", \"CA\", \"NY\", \"CA\", \"NY\", \"MA\"],\n",
    "    'owns car':[1,1,1,1,0,0,0]})\n",
    "print(df2)\n",
    "ce_woe = ce.WOEEncoder(verbose=1, cols = ['state'])\n",
    "ce_woe.fit_transform(df2['state'], df2['owns car'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [James-Stein](http://contrib.scikit-learn.org/categorical-encoding/jamesstein.html)\n",
    "\n",
    "The James-Stein estimator returns a weighted average of the mean target values of the observed feature value and of the overall values.\n",
    "\n",
    "You can check out the above link to see a more detailed explanation for how the values are calculated. Essentially, it provides a closed-form solution to determining appropriate weights (too much weight on the conditional mean value leads to overfitting and too little leads to underfitting). \n",
    "\n",
    "This estimator was only designed for normal distributions and can fail fatally for binary distributions (consider beta model if fatal errors occur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state  cars\n",
      "0    CA     3\n",
      "1    MA     1\n",
      "2    CA     2\n",
      "3    NY     0\n",
      "4    CA     4\n",
      "5    NY     1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state\n",
       "0   3.00\n",
       "1   1.00\n",
       "2   3.00\n",
       "3   0.50\n",
       "4   3.00\n",
       "5   0.50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df)\n",
    "ce_james = ce.JamesSteinEncoder(verbose=1, cols = ['state'])\n",
    "ce_james.fit_transform(df['state'], df['cars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [M-estimator](http://contrib.scikit-learn.org/categorical-encoding/mestimate.html)\n",
    "\n",
    "The M-estimator is essentially a simpler version of Target Encoding. M-estimator has only one tunable parameter (m) versus target encoder, which has two tunable parameters (min_samples_leaf and [smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)).\n",
    "\n",
    "In most cases where m-estimate encoding is applicable, LeaveOneOut Encoding should be considered first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state\n",
       "0   0.90\n",
       "1   0.24\n",
       "2   0.90\n",
       "3   0.24\n",
       "4   0.90\n",
       "5   0.24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_m = ce.MEstimateEncoder(cols = ['state'])\n",
    "ce_m.fit_transform(df['state'], df['cars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrast Encoders\n",
    "\n",
    "Contrast Encoders have a number of concerns that some argue make them suboptimal for machine learning. Try them with caution for specific situations, but know that they typically do not work for nominal variables. There are usually better alternatives that are more accurate (one-hot encoding) or have lower dimensions (LeaveOneOut, Hashing).\n",
    "\n",
    "This [guide](https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/) written by UCLA details Contrast Encoders in R, but does help explain a lot of the underlying calculations. This will need to be considered when deciding if Contrast Encoders should be used.\n",
    "\n",
    "The general logic is to capture the difference between each category with other categories, and, depending on this difference, separate/order them.\n",
    "\n",
    "### Helmert Encoding\n",
    "\n",
    "Compares the mean of the dependent variable for a level to the mean of the dependent variable over all of the previous values. This, in implementation, can be calculated through matrix multiplication.\n",
    "\n",
    "To illustrate how it works, if we have our 3 states, the first contrast would compare the mean of state 1 (`CA`) with the combined mean of states 2 and 3 (`MA` and `NY`). The second contrast would compare the mean of `MA` with `NY`. \n",
    "\n",
    "In practice, it looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intercept</th>\n",
       "      <th>state_0</th>\n",
       "      <th>state_1</th>\n",
       "      <th>state_2</th>\n",
       "      <th>state_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intercept  state_0  state_1  state_2  state_3\n",
       "0          1    -1.00    -1.00    -1.00    -1.00\n",
       "1          1     1.00    -1.00    -1.00    -1.00\n",
       "2          1    -1.00    -1.00    -1.00    -1.00\n",
       "3          1     0.00     2.00    -1.00    -1.00\n",
       "4          1    -1.00    -1.00    -1.00    -1.00\n",
       "5          1     0.00     2.00    -1.00    -1.00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_helmert = ce.HelmertEncoder(cols = ['state'])\n",
    "ce_helmert.fit_transform(df['state'], df['cars'])\n",
    "### This output is incorrect. Opened github issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum (Deviation) Encoding\n",
    "\n",
    "Sum Encoding works the same as Helmert encoding except it compares the mean of the dependent variable to the overall mean over all of the levels instead of just the previous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intercept</th>\n",
       "      <th>state_0</th>\n",
       "      <th>state_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intercept  state_0  state_1\n",
       "0          1     1.00     0.00\n",
       "1          1     0.00     1.00\n",
       "2          1     1.00     0.00\n",
       "3          1    -1.00    -1.00\n",
       "4          1     1.00     0.00\n",
       "5          1    -1.00    -1.00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_sum = ce.SumEncoder(cols = ['state'])\n",
    "ce_sum.fit_transform(df['state'], df['cars'])\n",
    "### This output is incorrect. Opened github issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Difference\n",
    "\n",
    "Similar to the previous two except the mean of the dependent variable is compared with the mean of only one level (the prior level)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Difference\n",
    "\n",
    "Polynomial encoding looks for linear, quadratic, cubic, or any degree trends. This is similar to interval encoding in the sense that categories may follow some sort of regularly increasing pattern, and polynomial encoding can determine that pattern if it fits a polynomial.\n",
    "\n",
    "This should be reserved for patterns that are uneven but still follow a definite, polynomial pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The go-to categorical encoding method should be one-hot encoding in almost every scenario (with the exception of decision-tree based algorithms). It is one of the most straightforward and easy to understand encoders, and also has no drawbacks with regards to machine learning model accuracy. The `encode_features()` function (Featuretools v0.9.0) currently uses one-hot encoding.\n",
    "\n",
    "However, in the cases with one-hot encoding leads to memory issues, namely datasets with high cardinality, it is necessary to use other encoders.\n",
    "\n",
    "Ordinal encoding works for a limited number of cases, but is usually the first step before applying other encoders (some libraries can only encode categorical values in an integer format).\n",
    "\n",
    "Among classic encoders, Binary and Hashing encoders can provide a straightforward and potentially effective way of reducing cardinality while retaining accuracy.\n",
    "\n",
    "However, the aforementioned two methods can lead to info loss, while Bayesian encoders offer a solution that solves both the cardinality and info loss problems. \n",
    "\n",
    "Strive to implement LeaveOneOut Encoding in scenarios where One-Hot encoding does not work, as this method deals with overfitting/response leakage problems that other Bayesian encoders struggle with.\n",
    "\n",
    "In certain situations, other Bayesian encoders may perform well, but a lot of thought should go into picking a different Bayesian encoder than LeaveOneOut.\n",
    "\n",
    "Finally, Contrast Encoders provide an interesting way to mathematically separate categories and determine patterns. However, it leads to the same cardinality issues as one-hot encoding and can be a lot more sensitive to errors. Only use Contrast encoding if you're sure, and consider one-hot encoding in such situations instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References/Additional Reading\n",
    "\n",
    "A compilation of links that I found useful when writing this guide (in addition to the links already in the notebook).\n",
    "\n",
    "#### Comparative Studies\n",
    "\n",
    "https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf\n",
    "\n",
    "http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/\n",
    "\n",
    "http://www.willmcginnis.com/2016/01/16/even-further-beyond-one-hot-hashing/\n",
    "\n",
    "\n",
    "#### Useful Reading on Feature Engineering/Categorical Encoding\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/encoding-methodologies\n",
    "\n",
    "https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b\n",
    "\n",
    "https://towardsdatascience.com/understanding-feature-engineering-part-2-categorical-data-f54324193e63\n",
    "\n",
    "https://towardsdatascience.com/smarter-ways-to-encode-categorical-data-for-machine-learning-part-1-of-3-6dca2f71b159\n",
    "\n",
    "#### Relevant to Target Encoding\n",
    "\n",
    "https://maxhalford.github.io/blog/target-encoding-done-the-right-way/\n",
    "\n",
    "https://medium.com/datadriveninvestor/improve-your-classification-models-using-mean-target-encoding-a3d573df31e8\n",
    "\n",
    "https://medium.com/datadriveninvestor/l1-l2-regularization-7f1b4fe948f2\n",
    "\n",
    "#### Bayesian Encoding\n",
    "\n",
    "https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#HELMERT\n",
    "\n",
    "#### Machine Learning Application Examples\n",
    "\n",
    "https://medium.com/airbnb-engineering/designing-machine-learning-models-7d0048249e69\n",
    "\n",
    "#### BaseN Encoding\n",
    "\n",
    "http://www.willmcginnis.com/2016/12/18/basen-encoding-grid-search-category_encoders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
